{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "* 'select' behaves kinda like a lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row - kinda like python dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "ridic zadie 1.5\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "row = Row(name='zadie',cuteness='ridic', age=1.5)\n",
    "print row['age']\n",
    "print row[1], row[2], row[0] # alphabetical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spark dataframe from python list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Seiji| 32|\n",
      "|Stephie| 30|\n",
      "|  Zadie|  1|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('Seiji', 32), ('Stephie', 30), ('Zadie', 1)]\n",
    "sqlc = SQLContext(sc)\n",
    "df = sqlc.createDataFrame(data, ['name','age'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Seiji| 32|\n",
      "|Stephie| 30|\n",
      "|  Zadie|  1|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Seiji| 32|\n",
      "|Stephie| 30|\n",
      "|  Zadie|  1|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('name', 'age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name|age+10|\n",
      "+-------+------+\n",
      "|  Seiji|    42|\n",
      "|Stephie|    40|\n",
      "|  Zadie|    11|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('name', (df['age']+10).alias('age+10')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|   name|age+10|age+100|\n",
      "+-------+------+-------+\n",
      "|  Seiji|    42|    132|\n",
      "|Stephie|    40|    130|\n",
      "|  Zadie|    11|    101|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('name', (df['age']+10).alias('age+10'), (df['age']+100).alias('age+100')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|  Seiji|\n",
      "|Stephie|\n",
      "|  Zadie|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(df['age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [('Seiji', 1), ('Stephie', 2), ('Zadie', 1)]\n",
    "data2 = [('Alice', 1), ('Bob', 2)]\n",
    "\n",
    "df = spark.createDataFrame(data,['name','age'])\n",
    "df2 = spark.createDataFrame(data2,['name','age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Seiji|  1|\n",
      "|Stephie|  2|\n",
      "|  Zadie|  1|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Alice|  1|\n",
      "|  Bob|  2|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Seiji|  1|\n",
      "|Stephie|  2|\n",
      "|  Zadie|  1|\n",
      "|  Alice|  1|\n",
      "|    Bob|  2|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.union(df2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name|slen|\n",
      "+-------+----+\n",
      "|  Seiji|   5|\n",
      "|Stephie|   7|\n",
      "|  Zadie|   5|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "slen = udf(lambda s: len(s), IntegerType())\n",
    "df.select('name', slen(df['name']).alias('slen')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "* filter\n",
    "* distint()\n",
    "* orderBy\n",
    "* sort\n",
    "* explode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>38</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>34</td>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>53</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>76</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>96</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e   f   g   h   i   j\n",
       "0  99  41  58   5   0  85  38  96   0  61\n",
       "1  54  34  88  99  64  11  66  37  70  67\n",
       "2  89   1  80  89  51   8  97   2  90  38\n",
       "3  25  53  13  35  76  92  91  86  11  87\n",
       "4  35   2  32  66  69  96  49  47  59  40\n",
       "5  97  61  15  25  94   0  64  35  36  26"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = 6,10\n",
    "panDf = pd.DataFrame(np.random.randint(100,size=(x,y)),\\\n",
    "                     columns=list(string.ascii_lowercase)[:y])\n",
    "panDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas to spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlc = SQLContext(sc)\n",
    "sparkDf = sqlc.createDataFrame(panDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "|  a|  b|  c|  d|  e|  f|  g|  h|  i|  j|\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "| 99| 41| 58|  5|  0| 85| 38| 96|  0| 61|\n",
      "| 54| 34| 88| 99| 64| 11| 66| 37| 70| 67|\n",
      "| 89|  1| 80| 89| 51|  8| 97|  2| 90| 38|\n",
      "| 25| 53| 13| 35| 76| 92| 91| 86| 11| 87|\n",
      "| 35|  2| 32| 66| 69| 96| 49| 47| 59| 40|\n",
      "| 97| 61| 15| 25| 94|  0| 64| 35| 36| 26|\n",
      "+---+---+---+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=99, b=41, c=58, d=5, e=0, f=85, g=38, h=96, i=0, j=61),\n",
       " Row(a=54, b=34, c=88, d=99, e=64, f=11, g=66, h=37, i=70, j=67)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDf.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=99, b=41, c=58, d=5, e=0, f=85, g=38, h=96, i=0, j=61),\n",
       " Row(a=54, b=34, c=88, d=99, e=64, f=11, g=66, h=37, i=70, j=67),\n",
       " Row(a=89, b=1, c=80, d=89, e=51, f=8, g=97, h=2, i=90, j=38),\n",
       " Row(a=25, b=53, c=13, d=35, e=76, f=92, g=91, h=86, i=11, j=87),\n",
       " Row(a=35, b=2, c=32, d=66, e=69, f=96, g=49, h=47, i=59, j=40),\n",
       " Row(a=97, b=61, c=15, d=25, e=94, f=0, g=64, h=35, i=36, j=26)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  a|\n",
      "+---+\n",
      "| 99|\n",
      "| 54|\n",
      "| 89|\n",
      "| 25|\n",
      "| 35|\n",
      "| 97|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDf.select('a').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=99, b=41), Row(a=54, b=34)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDf.select('a','b').take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a=99, b=41), Row(a=54, b=34)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDf.select(['a','b']).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkDf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabeledPoint rows from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(17.0, [50.0,61.0,19.0])]\n"
     ]
    }
   ],
   "source": [
    "featCols = ['a','b','c']\n",
    "\n",
    "labeledData = (sparkDf.map(\n",
    "        lambda row:\n",
    "        LabeledPoint(row['h'],\n",
    "                     Vectors.dense([row[el] for el in featCols])\n",
    "                    ))\n",
    "              )\n",
    "print labeledData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabeledPoint rows from DataFrame (method 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(17.0, [50.0,61.0,19.0])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=featCols,\n",
    "    outputCol=\"features\")\n",
    "\n",
    "transformed = assembler.transform(sparkDf)\n",
    "\n",
    "labeledData2 = (transformed.select(col(\"h\").alias(\"label\"), col(\"features\"))\n",
    "               .map(lambda row: LabeledPoint(row.label, row.features))\n",
    "              )\n",
    "labeledData2.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting distinct labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48.0, 16.0, 17.0, 66.0, 38.0, 31.0]\n"
     ]
    }
   ],
   "source": [
    "group_labels = labeledData2.map(lambda x: x.label).distinct().collect()\n",
    "print group_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding column based on logic of multiple column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "# credit: Austin in sparknotes slack channel 08-26\n",
    "def myFunc(row):\n",
    "    rowDict = row.asDict()\n",
    "    rowDict['d'] = 1 if rowDict['a'] < 0.5 or rowDict['b'] < 0.5 else 0\n",
    "    return Row(**rowDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparkDf2 = sparkDf.map(myFunc).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+---+\n",
      "|                  a|                 b|                 c|  d|\n",
      "+-------------------+------------------+------------------+---+\n",
      "| 0.6138643778719053|0.5633879152061312|0.9856763019891056|  0|\n",
      "|0.45372068691084566|0.9069223437838317|0.3839384600692365|  1|\n",
      "+-------------------+------------------+------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkDf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Seiji| 32|\n",
      "|Stephie| 30|\n",
      "|  Zadie|  1|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('Seiji', 32), ('Stephie', 30), ('Zadie', 1)]\n",
    "df = spark.createDataFrame(data,['name','age'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feeding in Row to function with *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+\n",
      "|min(age)|max(age)|avg(age)|\n",
      "+--------+--------+--------+\n",
      "|       1|      32|    21.0|\n",
      "+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as sqlFunctions\n",
    "\n",
    "sqlStats = df.agg(sqlFunctions.min(df['age']),\n",
    "       sqlFunctions.max(df['age']),\n",
    "       sqlFunctions.avg(df['age']))\n",
    "\n",
    "sqlStats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(min(age)=1, max(age)=32, avg(age)=21.0)\n",
      "min: 1, average: 21.0, max: 32\n"
     ]
    }
   ],
   "source": [
    "sqlStatsRow = sqlStats.first()\n",
    "print sqlStatsRow\n",
    "print 'min: {0}, average: {2}, max: {1}'.format(*sqlStatsRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select vs withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|age|          LOG(age)|\n",
      "+---+------------------+\n",
      "| 32|3.4657359027997265|\n",
      "| 30|3.4011973816621555|\n",
      "|  1|               0.0|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('age', sqlFunctions.log(df['age'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------------------+\n",
      "|   name|age|          log(age)|\n",
      "+-------+---+------------------+\n",
      "|  Seiji| 32|3.4657359027997265|\n",
      "|Stephie| 30|3.4011973816621555|\n",
      "|  Zadie|  1|               0.0|\n",
      "+-------+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('log(age)',sqlFunctions.log(df['age'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting StringIndexer label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"y\", outputCol=\"indexedLabel\").fit(signalDf)\n",
    "pd.DataFrame([(el,idx) for idx,el in enumerate(labelIndexer.labels)],columns=['y','indexedLabel'])\n",
    "labelMap = dict([(idx,el) for idx,el in enumerate(labelIndexer.labels)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
